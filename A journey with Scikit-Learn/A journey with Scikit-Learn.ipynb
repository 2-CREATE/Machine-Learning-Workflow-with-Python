{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1247188a5193a0bb99f176fea36dc594d283160e"
   },
   "source": [
    "## <div style=\"text-align: center\">A Journey with Scikit-Learn </div>\n",
    "\n",
    "<div style=\"text-align: center\">There are plenty of <b>courses and tutorials</b> that can help you learn Scikit-Learn from scratch but here in <b>Kaggle</b>, I want to predict <b>House prices</b>(in the next version)  a popular machine learning Dataset as a comprehensive workflow with Scikit-Learn. \n",
    "After reading, you can use this workflow to solve other real problems and use it as a template to deal with <b>machine learning</b> problems.</div>\n",
    "<div style=\"text-align:center\">last update: <b>10/15/2018</b></div>\n",
    "\n",
    "\n",
    "\n",
    ">###### you may  be interested have a look at it: [**A Comprehensive ML Workflow for House Prices**](https://www.kaggle.com/mjbahmani/a-comprehensive-ml-workflow-for-house-prices)\n",
    "\n",
    "\n",
    "---------------------------------------------------------------------\n",
    "you can follow me on:\n",
    "> ###### [ GitHub](https://github.com/mjbahmani)\n",
    "> ###### [Kaggle](https://www.kaggle.com/mjbahmani/)\n",
    "-------------------------------------------------------------------------------------------------------------\n",
    " **I hope you find this kernel helpful and some upvotes would be very much appreciated**\n",
    " \n",
    " -----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ec7344e7f2a1bafa9a44a518722fcd8ec47c374b"
   },
   "source": [
    "## 1-Introduction\n",
    "\n",
    "- The __open source__ Python ecosystem provides __a standalone, versatile and powerful scientific working environment__, including: [NumPy](http://numpy.org), [SciPy](http://scipy.org), [IPython](http://ipython.org), [Matplotlib](http://matplotlib.org), [Pandas](http://pandas.pydata.org/), _and many others..._\n",
    "\n",
    "\n",
    "\n",
    "- Scikit-Learn builds upon NumPy and SciPy and __complements__ this scientific environment with machine learning algorithms;\n",
    "- By design, Scikit-Learn is __non-intrusive__, easy to use and easy to combine with other libraries;\n",
    "- Core algorithms are implemented in low-level languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6e80040de557789b0dff267ce45ba3e494885fee"
   },
   "source": [
    "## 2- Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "666c206f83175114a513b37fb9ae322b5cd8543e"
   },
   "source": [
    "__Supervised learning:__\n",
    "\n",
    "* Linear models (Ridge, Lasso, Elastic Net, ...)\n",
    "* Support Vector Machines\n",
    "* Tree-based methods (Random Forests, Bagging, GBRT, ...)\n",
    "* Nearest neighbors \n",
    "* Neural networks (basics)\n",
    "* Gaussian Processes\n",
    "* Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "44eef8d741beebe15555c5166360b2ce77f5d5b1"
   },
   "source": [
    "__Unsupervised learning:__\n",
    "\n",
    "* Clustering (KMeans, Ward, ...)\n",
    "* Matrix decomposition (PCA, ICA, ...)\n",
    "* Density estimation\n",
    "* Outlier detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8da2cc5428b697a7b5f21d34038d343bb8b094bb"
   },
   "source": [
    "__Model selection and evaluation:__\n",
    "\n",
    "* Cross-validation\n",
    "* Grid-search\n",
    "* Lots of metrics\n",
    "\n",
    "_... and many more!_ (See our [Reference](http://scikit-learn.org/dev/modules/classes.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e8a877d51d20c1ad31bb635cffc89175426eb77c"
   },
   "source": [
    "## 3- Framework\n",
    "\n",
    "Data comes as a finite learning set ${\\cal L} = (X, y)$ where\n",
    "* Input samples are given as an array $X$ of shape `n_samples` $\\times$ `n_features`, taking their values in ${\\cal X}$;\n",
    "* Output values are given as an array $y$, taking _symbolic_ values in ${\\cal Y}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bafb45df9ecfe90563f2f9a1be8a327823cf6d35"
   },
   "source": [
    "The goal of supervised classification is to build an estimator $\\varphi: {\\cal X} \\mapsto {\\cal Y}$ minimizing\n",
    "\n",
    "$$\n",
    "Err(\\varphi) = \\mathbb{E}_{X,Y}\\{ \\ell(Y, \\varphi(X)) \\}\n",
    "$$\n",
    "\n",
    "where $\\ell$ is a loss function, e.g., the zero-one loss for classification $\\ell_{01}(Y,\\hat{Y}) = 1(Y \\neq \\hat{Y})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7efef8f514caf78e7bc2a60b4d5c0e7fa6d160ac"
   },
   "source": [
    "## 4- Applications\n",
    "\n",
    "- Classifying signal from background events; \n",
    "- Diagnosing disease from symptoms;\n",
    "- Recognising cats in pictures;\n",
    "- Identifying body parts with Kinect cameras;\n",
    "- ...\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7cc13baab79cbc6446763e4ebe8feba2c95e74c9"
   },
   "source": [
    "## 5- Data \n",
    "\n",
    "- Input data = Numpy arrays or Scipy sparse matrices ;\n",
    "- Algorithms are expressed using high-level operations defined on matrices or vectors (similar to MATLAB) ;\n",
    "    - Leverage efficient low-leverage implementations ;\n",
    "    - Keep code short and readable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "ea74e169f182b48bc12abc501df217e7c711157c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-6.45255647 -8.76358259]\n",
      " [ 0.28982141  0.14677196]\n",
      " [-5.18412293 -1.25347025]\n",
      " ...\n",
      " [-0.23142814 -1.60800704]\n",
      " [-0.60291835  6.87297279]\n",
      " [ 2.28425964  4.87408773]]\n",
      "['r' 'r' 'b' 'r' 'b']\n"
     ]
    }
   ],
   "source": [
    "# Generate data\n",
    "from sklearn.datasets import make_blobs\n",
    "import numpy as np\n",
    "X, y = make_blobs(n_samples=1000, centers=20, random_state=123)\n",
    "labels = [\"b\", \"r\"]\n",
    "y = np.take(labels, (y < 10))\n",
    "print(X) \n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "9430d1ac40a1d7ba715347c27039b9b0859e674a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "# X is a 2 dimensional array, with 1000 rows and 2 columns\n",
    "print(X.shape)\n",
    " \n",
    "# y is a vector of 1000 elements\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "0e4d94f4cde57a7f8aeaec876d0020b144fd7818"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.28982141  0.14677196]\n",
      " [-5.18412293 -1.25347025]\n",
      " [-4.71388847  3.67440463]]\n",
      "[[-6.45255647 -8.76358259]\n",
      " [ 0.28982141  0.14677196]\n",
      " [-5.18412293 -1.25347025]\n",
      " [-4.71388847  3.67440463]\n",
      " [ 4.51558296 -2.88138033]]\n",
      "[-4.43836309 -2.45974437  4.33104832 -7.92069399  1.56972029  0.56451501\n",
      "  4.99608298  4.75811106 -1.60421418  1.10129122]\n",
      "[[-5.18412293 -1.25347025]\n",
      " [ 4.51558296 -2.88138033]\n",
      " [ 1.70826922  2.62387342]\n",
      " [-0.52606562  8.95985097]\n",
      " [-1.07591403  9.78730967]]\n"
     ]
    }
   ],
   "source": [
    "# Rows and columns can be accessed with lists, slices or masks\n",
    "print(X[[1, 2, 3]])     # rows 1, 2 and 3\n",
    "print(X[:5])            # 5 first rows\n",
    "print(X[500:510, 0])    # values from row 500 to row 510 at column 0\n",
    "print(X[y == \"b\"][:5])  # 5 first rows for which y is \"b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "f87a77afd2c6d75c7d20390394a1f9ae569a30dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2c6b40085c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 8)\n",
    "plt.rcParams[\"figure.max_open_warning\"] = -1\n",
    "plt.figure()\n",
    "for label in labels:\n",
    "    mask = (y == label)\n",
    "    plt.scatter(X[mask, 0], X[mask, 1], c=label)\n",
    "plt.xlim(-10, 10)\n",
    "plt.ylim(-10, 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "af3faf3d05bc406b6d882f527f5f5637c4e572a8"
   },
   "source": [
    "## 6- Loading external data\n",
    "\n",
    "- Numpy provides some [simple tools](https://docs.scipy.org/doc/numpy/reference/routines.io.html) for loading data from files (CSV, binary, etc);\n",
    "\n",
    "- For structured data, Pandas provides more [advanced tools](http://pandas.pydata.org/pandas-docs/stable/io.html) (CSV, JSON, Excel, HDF5, SQL, etc);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d8307c56699bb79ffb7b3b9e62532b8dab8f7761"
   },
   "source": [
    "## 7- A simple and unified API\n",
    "\n",
    "All learning algorithms in scikit-learn share a uniform and limited API consisting of complementary interfaces:\n",
    "\n",
    "- an `estimator` interface for building and fitting models;\n",
    "- a `predictor` interface for making predictions;\n",
    "- a `transformer` interface for converting data.\n",
    "\n",
    "Goal: enforce a simple and consistent API to __make it trivial to swap or plug algorithms__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bc2471a2bc5d24fbee0532a71219e8b25996c20c"
   },
   "source": [
    "### 8- Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "ae2c9909a05b213a567338be03f0b880dcbc42fd"
   },
   "outputs": [],
   "source": [
    "class Estimator(object):\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Fits estimator to data.\"\"\"\n",
    "        # set state of ``self``\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "c7c25b799b47dd172f3f73e2c85d2670b0095124"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the nearest neighbor class\n",
    "from sklearn.neighbors import KNeighborsClassifier  # Change this to try \n",
    "                                                    # something else\n",
    "\n",
    "# Set hyper-parameters, for controlling algorithm\n",
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Learn a model from training data\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "f3813605cc909c6fecd52a12e2edc37ad4cc42c2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.neighbors.kd_tree.KDTree at 0x2c6b2942588>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimator state is stored in instance attributes\n",
    "clf._tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0984dea25e9a6c6c7b7372057f87c4bacd230375"
   },
   "source": [
    "### 9- Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "9ca84979bfe46e0b6ce79ade03ac19efde72f5c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['r' 'r' 'r' 'b' 'b']\n"
     ]
    }
   ],
   "source": [
    "# Make predictions  \n",
    "print(clf.predict(X[:5])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "1b12ceaf8ca499e5e7d3486955f281f5bd72f34b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.  1. ]\n",
      " [0.  1. ]\n",
      " [0.2 0.8]\n",
      " [0.6 0.4]\n",
      " [0.8 0.2]]\n"
     ]
    }
   ],
   "source": [
    "# Compute (approximate) class probabilities\n",
    "print(clf.predict_proba(X[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f35127982cf5b2febee5bf9f7562762ee282f1dc"
   },
   "source": [
    "### 10- Decision trees\n",
    "\n",
    "Idea: greedily build a partition of the input space using cuts orthogonal to feature axes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f11015dffa601b08e4d2b6ac3f024694839b7937"
   },
   "source": [
    "### 11- Random Forests\n",
    "\n",
    "Idea: Build several decision trees with controlled randomness and average their decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0f6fdaa22671674443d3f1bff6ae0bf372e75359"
   },
   "source": [
    "### 12- Logistic regression\n",
    "\n",
    "Idea: model the decision boundary as an hyperplane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3adcd919ed2545f9b915ddc08cac10011be2f3dc"
   },
   "source": [
    "### 13-Support vector machines\n",
    "\n",
    "Idea: Find the hyperplane which has the largest distance to the nearest training points of any class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d0b08c8c82b81382c12ae859991f9657808f8a98"
   },
   "source": [
    "### 14- Multi-layer perceptron\n",
    "\n",
    "Idea: a multi-layer perceptron is a circuit of non-linear combinations of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "96edb0d1ff220f45ff4ed675274399b33d82f1cc"
   },
   "outputs": [],
   "source": [
    "# Model evaluation and selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7e2b213a37847110d05a0c90d7c5c33f9aefb228"
   },
   "source": [
    "## 15- Evaluation\n",
    "\n",
    "- Recall that we want to learn an estimator $\\varphi$ minimizing the generalization error $Err(\\varphi) = \\mathbb{E}_{X,Y}\\{ \\ell(Y, \\varphi(X)) \\}$.\n",
    "\n",
    "- Problem: Since $P_{X,Y}$ is unknown, the generalization error $Err(\\varphi)$ cannot be evaluated.\n",
    "\n",
    "- Solution: Use a proxy to approximate $Err(\\varphi)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "22f5ef117e03d54401413e162f5d8c023953dda4"
   },
   "source": [
    "## 16- Training error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "2cf59c5ba23a9d7b5bd931372002f911d5a8e6f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error = 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import zero_one_loss\n",
    "clf = KNeighborsClassifier(n_neighbors=1)\n",
    "clf.fit(X, y)\n",
    "print(\"Training error =\", zero_one_loss(y, clf.predict(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c03e9024b8c512dc8bbafe93074dd077ae016c28"
   },
   "source": [
    "## 17 - Test error\n",
    "\n",
    "Issue: the training error is a __biased__ estimate of the generalization error.\n",
    "\n",
    "Solution: Divide ${\\cal L}$ into two disjoint parts called training and test sets (usually using 70% for training and 30% for test).\n",
    "- Use the training set for fitting the model;\n",
    "- Use the test set for evaluation only, thereby yielding an unbiased estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "caf35db8de547a3994b837be4e95d446683be305"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error = 0.10666666666666669\n",
      "Test error = 0.18400000000000005\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Training error =\", zero_one_loss(y_train, clf.predict(X_train)))\n",
    "print(\"Test error =\", zero_one_loss(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "db40db7313dbc0ba56058101810dd5177c43a83b"
   },
   "source": [
    "Summary: Beware of bias when you estimate model performance:\n",
    "- Training score is often an optimistic estimate of the true performance;\n",
    "- __The same data should not be used both for training and evaluation.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "953b31ec46a7a55ba984c2e043033362bca3c2fc"
   },
   "source": [
    "## 18- Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6ae5deaa807d06338b4cf05c3b2df6649c673dd1"
   },
   "source": [
    "Issue: \n",
    "- When ${\\cal L}$ is small, training on 70% of the data may lead to a model that is significantly different from a model that would have been learned on the entire set ${\\cal L}$. \n",
    "- Yet, increasing the size of the training set (resp. decreasing the size of the test set), might lead to an inaccurate estimate of the generalization error. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bc9008ff6bffa47cf1c4e834724113df52ae8a30"
   },
   "source": [
    "Solution: K-Fold cross-validation. \n",
    "- Split ${\\cal L}$ into K small disjoint folds. \n",
    "- Train on K-1 folds, evaluate the test error one the held-out fold.\n",
    "- Repeat for all combinations and average the K estimates of the generalization error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "b0bf80dea0982187171e5802fe9281632e9fabfe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV error = 0.163000 +-0.010770\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "scores = []\n",
    "\n",
    "for train, test in KFold(n_splits=5, random_state=42).split(X):\n",
    "    X_train, y_train = X[train], y[train]\n",
    "    X_test, y_test = X[test], y[test]\n",
    "    clf = KNeighborsClassifier(n_neighbors=5).fit(X_train, y_train)\n",
    "    scores.append(zero_one_loss(y_test, clf.predict(X_test)))\n",
    "\n",
    "print(\"CV error = %f +-%f\" % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1923ba01df86012077df2a2750b92ebb2adb8236"
   },
   "source": [
    "## References\n",
    "1. [Coursera](https://www.coursera.org/specializations/data-science-python)\n",
    "1. [GitHub](https://github.com/glouppe/tutorials-scikit-learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4427b5491761efbc8c7c293881cafbe655d74ed9",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
